FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive

# Python 3.11 via deadsnakes (Ubuntu 22.04 ships 3.10) + cuDNN 9 from
# the NVIDIA CUDA repo already configured in the base image.
RUN apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
 && add-apt-repository -y ppa:deadsnakes/ppa \
 && apt-get update && apt-get install -y --no-install-recommends \
    python3.11 python3.11-venv python3.11-distutils \
    ffmpeg \
    libcudnn9-cuda-12 \
    git \
 && ln -sf /usr/bin/python3.11 /usr/bin/python \
 && python -m ensurepip --upgrade \
 && apt-get purge -y software-properties-common \
 && apt-get autoremove -y && rm -rf /var/lib/apt/lists/*

# Install tts-audiobook-tool from our fork (pinned commit).
# chatterbox-tts 0.1.6 hard-pins torch==2.6.0 which only ships cu124+.
# Install torch from the cu124 index first so the solver respects the pin,
# then the full requirements file which covers chatterbox-tts, faster-whisper,
# and all audio-processing dependencies.
ARG TTS_TOOL_COMMIT=a4875021374ab95b0ad36213639194807a5039a1
RUN git clone https://github.com/yonch/tts-audiobook-tool.git /opt/tts-audiobook-tool \
 && cd /opt/tts-audiobook-tool && git checkout $TTS_TOOL_COMMIT \
 && python -m pip install --no-cache-dir \
    torch==2.6.0 torchaudio==2.6.0 \
    --index-url https://download.pytorch.org/whl/cu124 \
 && python -m pip install --no-cache-dir \
    -r /opt/tts-audiobook-tool/requirements-chatterbox.txt \
 && python -m pip install --no-cache-dir -e /opt/tts-audiobook-tool \
 && python -m pip install --no-cache-dir requests onnxruntime

# Ensure standalone modules in the tts-audiobook-tool root (e.g.
# yamnet_detector) are importable.  pip install -e only exposes packages
# found by setuptools find_packages(), which misses bare .py files.
ENV PYTHONPATH="/opt/tts-audiobook-tool${PYTHONPATH:+:$PYTHONPATH}"

# Bake Chatterbox model weights into the image so the GPU node has no
# runtime dependency on HuggingFace.
RUN python -c "from chatterbox.tts import ChatterboxTTS; ChatterboxTTS.from_pretrained(device='cpu')"

# Bake faster-whisper medium model weights.
RUN python -c "from faster_whisper import WhisperModel; WhisperModel('medium', device='cpu', compute_type='int8', download_root='/models/whisper')"

# Bake YAMNet ONNX model weights (used for music detection).
RUN python -c "from huggingface_hub import hf_hub_download; hf_hub_download(repo_id='zeropointnine/yamnet-onnx', filename='yamnet.onnx')"

COPY run.py /app/run.py

WORKDIR /app
CMD ["python", "run.py"]
