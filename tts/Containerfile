FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive

# Python 3.11 via deadsnakes (Ubuntu 22.04 ships 3.10) + cuDNN 9 from
# the NVIDIA CUDA repo already configured in the base image.
RUN apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
 && add-apt-repository -y ppa:deadsnakes/ppa \
 && apt-get update && apt-get install -y --no-install-recommends \
    python3.11 python3.11-venv python3.11-distutils \
    ffmpeg \
    libcudnn9-cuda-12 \
 && ln -sf /usr/bin/python3.11 /usr/bin/python \
 && python -m ensurepip --upgrade \
 && apt-get purge -y software-properties-common \
 && apt-get autoremove -y && rm -rf /var/lib/apt/lists/*

# chatterbox-tts 0.1.6 hard-pins torch==2.6.0 which only ships cu124+.
# Install torch + torchvision from the cu124 index first, then the app
# deps in a single pip invocation so the solver respects the pin.
RUN pip install --no-cache-dir \
    torch==2.6.0 torchvision==0.21.0 \
    --index-url https://download.pytorch.org/whl/cu124 \
 && pip install --no-cache-dir \
    chatterbox-tts \
    openai-whisper \
    pysbd \
    pyloudnorm \
    soundfile \
    requests

# Bake Chatterbox model weights into the image so the GPU node has no
# runtime dependency on HuggingFace.
RUN python -c "from chatterbox.tts import ChatterboxTTS; ChatterboxTTS.from_pretrained(device='cpu')"

# Bake Whisper medium model weights (~1.5 GB).
RUN python -c "import whisper; whisper.load_model('medium', download_root='/models/whisper')"

COPY run.py /app/run.py

WORKDIR /app
ENV WHISPER_DOWNLOAD_ROOT=/models/whisper
CMD ["python", "run.py"]
